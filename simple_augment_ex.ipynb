{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import random\n",
    "import zarr\n",
    "from skimage import data\n",
    "from skimage import filters\n",
    "\n",
    "# set upsample factor for demo\n",
    "up_factor = 3\n",
    "\n",
    "# make sure we all see the same\n",
    "np.random.seed(19623)\n",
    "random.seed(19623)\n",
    "\n",
    "# open a sample image (channels first)\n",
    "raw_data = data.astronaut().transpose(2, 0, 1)\n",
    "\n",
    "# create some dummy \"ground-truth\" to train on\n",
    "gt_data = filters.gaussian(raw_data[0], sigma=3.0) > 0.75\n",
    "gt_data = gt_data[np.newaxis,:].astype(np.float32)\n",
    "\n",
    "# store image in zarr container\n",
    "f = zarr.open('sample_data.zarr', 'w')\n",
    "f['raw'] = raw_data\n",
    "f['raw'].attrs['resolution'] = (up_factor, up_factor)\n",
    "f['ground_truth'] = gt_data\n",
    "f['ground_truth'].attrs['resolution'] = (up_factor, up_factor)\n",
    "\n",
    "# helper function to show image(s), channels first\n",
    "def imshow(raw, ground_truth=None, prediction=None):\n",
    "  rows = 1\n",
    "  if ground_truth is not None:\n",
    "    rows += 1\n",
    "  if prediction is not None:\n",
    "    rows += 1\n",
    "  cols = raw.shape[0] if len(raw.shape) > 3 else 1\n",
    "  fig, axes = plt.subplots(rows, cols, figsize=(10, 4), sharex=True, sharey=True, squeeze=False)\n",
    "  if len(raw.shape) == 3:\n",
    "    axes[0][0].imshow(raw.transpose(1, 2, 0))\n",
    "  else:\n",
    "    for i, im in enumerate(raw):\n",
    "      axes[0][i].imshow(im.transpose(1, 2, 0))\n",
    "  row = 1\n",
    "  if ground_truth is not None:\n",
    "    if len(ground_truth.shape) == 3:\n",
    "      axes[row][0].imshow(ground_truth[0])\n",
    "    else:\n",
    "      for i, gt in enumerate(ground_truth):\n",
    "        axes[row][i].imshow(gt[0])\n",
    "    row += 1\n",
    "  if prediction is not None:\n",
    "    if len(prediction.shape) == 3:\n",
    "      axes[row][0].imshow(prediction[0])\n",
    "    else:\n",
    "      for i, gt in enumerate(prediction):\n",
    "        axes[row][i].imshow(gt[0])\n",
    "  plt.show()"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "import gunpowder as gp\n",
    "import torch\n",
    "from funlib.learn.torch.models import UNet, ConvPass\n",
    "\n",
    "# make sure we all see the same\n",
    "torch.manual_seed(18)\n",
    "\n",
    "unet = UNet(\n",
    "  in_channels=3,\n",
    "  num_fmaps=4,\n",
    "  fmap_inc_factor=2,\n",
    "  downsample_factors=[[2, 2], [2, 2]],\n",
    "  kernel_size_down=[[[3, 3], [3, 3]]]*3,\n",
    "  kernel_size_up=[[[3, 3], [3, 3]]]*2,\n",
    "  padding='same')\n",
    "\n",
    "model = torch.nn.Sequential(\n",
    "  unet,\n",
    "  ConvPass(4, 1, [(1, 1)], activation=None),\n",
    "  torch.nn.Sigmoid())\n",
    "\n",
    "loss = torch.nn.BCELoss()\n",
    "\n",
    "optimizer = torch.optim.Adam(model.parameters())\n",
    "\n",
    "# declare arrays to use in the pipeline\n",
    "raw = gp.ArrayKey('RAW')\n",
    "\n",
    "# create \"pipeline\" consisting only of a data source\n",
    "source = gp.ZarrSource(\n",
    "    'sample_data.zarr',  # the zarr container\n",
    "    {raw: 'raw'},  # which dataset to associate to the array key\n",
    "    {raw: gp.ArraySpec(interpolatable=True)}  # meta-information\n",
    ")\n",
    "pipeline = source\n",
    "\n",
    "# create new array key for the network output\n",
    "prediction = gp.ArrayKey('PREDICTION')\n",
    "\n",
    "# create a train node using our model, loss, and optimizer\n",
    "train = gp.torch.Train(\n",
    "  model,\n",
    "  loss,\n",
    "  optimizer,\n",
    "  inputs = {\n",
    "    'input': raw\n",
    "  },\n",
    "  loss_inputs = {\n",
    "    0: prediction,\n",
    "    1: gt\n",
    "  },\n",
    "  outputs = {\n",
    "    0: prediction\n",
    "  })\n",
    "\n",
    "pipeline = (\n",
    "  source +\n",
    "  normalize +\n",
    "  random_location +\n",
    "  simple_augment +\n",
    "  elastic_augment +\n",
    "  intensity_augment +\n",
    "  noise_augment +\n",
    "  stack +\n",
    "  train)\n",
    "\n",
    "# add the prediction to the request\n",
    "request[prediction] = gp.Roi((0, 0), (64, 128))\n",
    "\n",
    "with gp.build(pipeline):\n",
    "  batch = pipeline.request_batch(request)\n",
    "\n",
    "imshow(batch[raw].data, batch[gt].data, batch[prediction].data)"
   ],
   "outputs": [],
   "metadata": {}
  }
 ],
 "metadata": {
  "orig_nbformat": 4,
  "language_info": {
   "name": "python",
   "version": "3.7.10",
   "mimetype": "text/x-python",
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "pygments_lexer": "ipython3",
   "nbconvert_exporter": "python",
   "file_extension": ".py"
  },
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3.7.10 64-bit ('n2v': conda)"
  },
  "interpreter": {
   "hash": "f9cb357f91f63a353a1c2ecd5237cebe3ac17167e08747c30b5061e5be51817e"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}