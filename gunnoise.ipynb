{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "## Imports"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "source": [
    "# !conda activate n2v\n",
    "%load_ext autoreload\n",
    "\n",
    "import numpy as np\n",
    "# from matplotlib import pyplot as plt\n",
    "import sys\n",
    "import random\n",
    "import zarr\n",
    "from PIL import Image\n",
    "from skimage import data\n",
    "from skimage import filters\n",
    "from skimage import metrics\n",
    "\n",
    "import gunpowder as gp\n",
    "import logging\n",
    "logging.basicConfig(level=logging.INFO)\n",
    "\n",
    "# from this repo\n",
    "# from segway.tasks.make_zarr_from_tiff import task_make_zarr_from_tiff_volume as tif2zarr\n",
    "from boilerPlate import GaussBlur"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "source": [
    "# ADD HELPER FUNCTIONS\n",
    "\n",
    "def noise_pipe(src, target, pipeline, noise_order, noise_dict):\n",
    "    this_array = src\n",
    "    for noise in noise_order:\n",
    "        if noise_dict[noise]:\n",
    "            if noise =='downX' and noise_dict[noise]:\n",
    "                pipeline += gp.DownSample(src, (1, noise_dict[noise], noise_dict[noise]), target) # assumes zyx coordinates (and non-isometric)\n",
    "                this_array = target\n",
    "            elif noise =='gaussBlur' and noise_dict[noise]:\n",
    "                pipeline += GaussBlur(this_array, noise_dict[noise])\n",
    "            elif noise =='gaussNoise' and noise_dict[noise]:\n",
    "                pipeline += gp.NoiseAugment(this_array, mode='gaussian', var=noise_dict[noise])\n",
    "            elif noise =='poissNoise' and noise_dict[noise]:\n",
    "                pipeline += gp.NoiseAugment(this_array, mode='poisson')\n",
    "            # elif noise =='deform' and noise_dict[noise]: # TODO: IMPLEMENT\n",
    "            #     pipeline += ...\n",
    "\n",
    "    return pipeline"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Specify Parameters (source, noise type, downsampling, etc.)"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "source": [
    "noise_version = '' # for making multiple independently generated noise versions (e.g. for Fourier Shell analysis)\n",
    "src_path = '/n/groups/htem/ESRF_id16a/tomo_ML/synapse/cb2/' # PATH FOR ZARR\n",
    "\n",
    "raw_name = 'raw'\n",
    "noise_dict = {'downX': 8, # cudegy mimic of 30nm pixel size (max uttained) from sensor at ESRF.i16a X-ray source, assuming 4nm voxel size EM source images\n",
    "         'gaussBlur': 30, # cudegy mimic of 30nm resolution of KB mirrors at ESRF.i16a X-ray source\n",
    "         'gaussNoise': None, # ASSUMES MEAN = 0, THIS SETS VARIANCE\n",
    "         'poissNoise': True, # cudegy mimic of sensor shot noise (hot pixels) at ESRF.i16a X-ray source\n",
    "        #  'deform': , # TODO: IMPLEMENT\n",
    "         }\n",
    "\n",
    "noise_order = ['gaussBlur', \n",
    "               'downX', \n",
    "               'gaussNoise', \n",
    "               'poissNoise'\n",
    "               ]\n",
    "\n",
    "# noise_order = ['downX', \n",
    "#                'gaussBlur', \n",
    "#                'gaussNoise', \n",
    "#                'poissNoise'\n",
    "#                ]\n",
    "\n",
    "samples = [\n",
    "    # 'ml0', # should be already done\n",
    "    #'ml1',\n",
    "    #'cutout1',\n",
    "    #'cutout2',\n",
    "    'cutout5',\n",
    "    'cutout6',\n",
    "    'cutout7',\n",
    "    ]\n",
    "\n",
    "src_voxel_size = (40, 4, 4)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "source": [
    "##### BELOW IS AUTOMATIC PARAMETER SETUP BASED ON ABOVE SPECIFICATIONS ######\n",
    "\n",
    "noise_name = ''\n",
    "for noise in noise_order:\n",
    "    if noise_dict[noise]:\n",
    "        if str(noise_dict[noise]).isnumeric():\n",
    "            noise_name += noise + str(noise_dict[noise]) + '_'\n",
    "        elif isinstance(noise_dict[noise], bool):\n",
    "            noise_name += noise + '_'\n",
    "\n",
    "if noise_version == '':\n",
    "    noise_name = noise_name[:-1]\n",
    "else:\n",
    "    noise_name += noise_version\n",
    "\n",
    "print('Layer name for noised data: ' + noise_name)\n",
    "\n",
    "if noise_dict['downX']:\n",
    "    dest_voxel_size = [src_voxel_size[s] * noise_dict['downX'] if s > 0 else src_voxel_size[s] for s in range(len(src_voxel_size))]\n",
    "else:\n",
    "    dest_voxel_size = src_voxel_size\n",
    "src_voxel_size = gp.Coordinate(src_voxel_size)\n",
    "dest_voxel_size = gp.Coordinate(dest_voxel_size)\n"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Layer name for noised data: gaussBlur30_downX8_poissNoise\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Setup Noising Pipeline"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "source": [
    "%autoreload\n",
    "from boilerPlate import GaussBlur"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "source": [
    "# assemble pipeline for each volume and run\n",
    "for sample in samples:    \n",
    "        # declare arrays to use in the pipeline\n",
    "        raw = gp.ArrayKey('RAW') # raw data\n",
    "        noisy = gp.ArrayKey('NOISY') # data noise added\n",
    "        raw_spec = gp.ArraySpec(voxel_size=src_voxel_size, interpolatable=True)\n",
    "\n",
    "        stack = gp.Stack(8)\n",
    "\n",
    "        # request matching the model input and output sizes\n",
    "        scan_request = gp.BatchRequest()\n",
    "        scan_request.add(raw, (40, 256, 256))#, src_voxel_size)\n",
    "        scan_request.add(noisy, (40, 256, 256))#, dest_voxel_size)\n",
    "        # scan_request[noisy].dtype = np.float64\n",
    "\n",
    "        scan = gp.Scan(scan_request, num_workers=4)\n",
    "\n",
    "        # request an empty batch from scan\n",
    "        request = gp.BatchRequest()\n",
    "\n",
    "        # setup Cache\n",
    "        cache = gp.PreCache()\n",
    "\n",
    "        # get performance stats\n",
    "        performance = gp.PrintProfilingStats(every=100)\n",
    "        # $src_path$volume/$volume.zarr/volumes/$layer\n",
    "        src = f'{src_path}{sample}/{sample}.zarr/volumes'\n",
    "        zarr.open(src)\n",
    "        source = gp.ZarrSource(    # add the data source\n",
    "                src,  # the zarr container\n",
    "                {raw: raw_name},  # which dataset to associate to the array key\n",
    "                {raw: raw_spec}  # meta-information\n",
    "        )\n",
    "\n",
    "        destination = gp.ZarrWrite(\n",
    "                dataset_names = {noisy: noise_name},\n",
    "                output_dir = f'{src_path}{sample}',\n",
    "                output_filename = f'{sample}.zarr/volumes',\n",
    "                dataset_dtypes = {noisy: np.uint8} # save as 0-255 values (should match raw)\n",
    "        )\n",
    "\n",
    "        pipeline = (noise_pipe(raw, noisy, source, noise_order, noise_dict) + \n",
    "                        #cache +\n",
    "                        #stack + \n",
    "                        destination + \n",
    "                        scan + \n",
    "                        performance)\n",
    "        \n",
    "        with gp.build(pipeline):\n",
    "                pipeline.request_batch(request)\n",
    "                print('Finished: ' + src)\n"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "INFO:gunpowder.nodes.scan:scanning over 204800 chunks\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "source": [
    "test = zarr.open('/n/groups/htem/ESRF_id16a/tomo_ML/synapse/cb2/cutout5/cutout5.zarr/volumes')\n",
    "test.info"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "Name        : /\n",
       "Type        : zarr.hierarchy.Group\n",
       "Read-only   : False\n",
       "Store type  : zarr.storage.DirectoryStore\n",
       "No. members : 2\n",
       "No. arrays  : 1\n",
       "No. groups  : 1\n",
       "Arrays      : raw\n",
       "Groups      : labels"
      ],
      "text/html": [
       "<table class=\"zarr-info\"><tbody><tr><th style=\"text-align: left\">Name</th><td style=\"text-align: left\">/</td></tr><tr><th style=\"text-align: left\">Type</th><td style=\"text-align: left\">zarr.hierarchy.Group</td></tr><tr><th style=\"text-align: left\">Read-only</th><td style=\"text-align: left\">False</td></tr><tr><th style=\"text-align: left\">Store type</th><td style=\"text-align: left\">zarr.storage.DirectoryStore</td></tr><tr><th style=\"text-align: left\">No. members</th><td style=\"text-align: left\">2</td></tr><tr><th style=\"text-align: left\">No. arrays</th><td style=\"text-align: left\">1</td></tr><tr><th style=\"text-align: left\">No. groups</th><td style=\"text-align: left\">1</td></tr><tr><th style=\"text-align: left\">Arrays</th><td style=\"text-align: left\">raw</td></tr><tr><th style=\"text-align: left\">Groups</th><td style=\"text-align: left\">labels</td></tr></tbody></table>"
      ]
     },
     "metadata": {},
     "execution_count": 21
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [],
   "outputs": [],
   "metadata": {}
  }
 ],
 "metadata": {
  "orig_nbformat": 4,
  "language_info": {
   "name": "python",
   "version": "3.7.10",
   "mimetype": "text/x-python",
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "pygments_lexer": "ipython3",
   "nbconvert_exporter": "python",
   "file_extension": ".py"
  },
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3.7.10 64-bit ('n2v': conda)"
  },
  "interpreter": {
   "hash": "f9cb357f91f63a353a1c2ecd5237cebe3ac17167e08747c30b5061e5be51817e"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}