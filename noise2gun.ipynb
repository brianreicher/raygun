{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "# Imports"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "source": [
    "# !conda activate n2v\n",
    "\n",
    "import numpy as np\n",
    "from matplotlib import pyplot as plt\n",
    "import sys\n",
    "import torch\n",
    "import random\n",
    "import zarr\n",
    "from skimage import data\n",
    "from skimage import filters\n",
    "from skimage import metrics\n",
    "\n",
    "from funlib.learn.torch.models import UNet, ConvPass\n",
    "import gunpowder as gp\n",
    "\n",
    "# from this repo\n",
    "import loser"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Set Parameters (including data source, training variables, destination, etc.)"
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## **Paths for training, predictions and results**\n",
    "\n",
    "**`train_source:`:** This is the path to your folders containing the Training_source (noisy images). To find the path of the folder containing your datasets, go to your Files on the left of the notebook, navigate to the folder containing your files and copy the path by right-clicking on the folder, **Copy path** and pasting it into the right box below.\n",
    "\n",
    "**`model_name`:** Use only my_model -style, not my-model (Use \"_\" not \"-\"). Do not use spaces in the name. Do not re-use the name of an existing model (saved in the same folder), otherwise it will be overwritten.\n",
    "\n",
    "**`model_path`**: Enter the path where your model will be saved once trained (for instance your result folder).\n",
    "\n",
    "\n",
    "## **Training parameters**\n",
    "\n",
    "**`num_epochs`:** Input how many epochs (rounds) the network will be trained. Preliminary results can already be observed after a few (10-30) epochs, but a full training should run for 100-200 epochs. Evaluate the performance after training (see 5.). **Default value: 30**\n",
    "\n",
    "**`side_length`:** Noise2Void divides the image into patches for training. Input the size of the patches (length of a side). The value should be smaller than the dimensions of the image and divisible by 8. **Default value: 100**\n",
    "\n",
    "**If you get an Out of memory (OOM) error during the training, manually decrease the patch_size values until the OOM error disappear.**\n",
    "\n",
    "**`batch_size:`** This parameter defines the number of patches seen in each training step. Noise2Void requires a large batch size for stable training. Reduce this parameter if your GPU runs out of memory. **Default value: 1**\n",
    "\n",
    "**`num_steps`:** Define the number of training steps by epoch. By default this parameter is calculated so that each image / patch is seen at least once per epoch. **Default value: Number of patch / batch_size**\n",
    "\n",
    "**`perc_validation`:**  Input the percentage of your training dataset you want to use to validate the network during the training. **Default value: 10** \n",
    "\n",
    "**`init_learn_rate`:** Input the initial value to be used as learning rate. **Default value: 0.0004**\n",
    "\n",
    "**`perc_hotPixels:`** Percent of output pixels to designate as targets and *heat* for training **Default value: 0.198**\n"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "source": [
    "train_source = ''\n",
    "model_name = 'noise2gun_mCTX30nm_450p'\n",
    "model_path = ''\n",
    "\n",
    "num_epochs = 100\n",
    "side_length = 100\n",
    "batch_size = 1\n",
    "num_steps = 100\n",
    "perc_validation = 10\n",
    "init_learn_rate = 0.0004\n",
    "perc_hotPixels = 0.198"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Make sure data source is a **zarr** "
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Build Gunpowder Pipeline for Training\n",
    "\n",
    "### Elements are:\n",
    "\n",
    "- Data Source\n",
    "- *(optional) Normalization*\n",
    "- Random Patch Grab\n",
    "- Pixel Heating (select and mutate *hotPixels*, i.e. training targets, and keep masks)\n",
    "- Simple Augmentation (rotations/reflections)\n",
    "- Stacking\n",
    "- Training\n"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# declare arrays to use in the pipeline\n",
    "raw = gp.ArrayKey('RAW') # raw data\n",
    "hot = gp.ArrayKey('HOT') # data with random pixels heated\n",
    "mask = gp.ArrayKey('MASK') # data with random pixels heated\n",
    "prediction = gp.ArrayKey('PREDICTION') # prediction of denoised data\n",
    "\n",
    "source = gp.ZarrSource(    # add the data source\n",
    "    train_source,  # the zarr container\n",
    "    {raw: 'raw'},  # which dataset to associate to the array key\n",
    "    {raw: gp.ArraySpec(interpolatable=True)}  # meta-information\n",
    ")\n",
    "\n",
    "# add normalization\n",
    "# normalize = gp.Normalize(raw)\n",
    "\n",
    "# add a RandomLocation node to the pipeline to randomly select a sample\n",
    "random_location = gp.RandomLocation()\n",
    "\n",
    "# add transpositions/reflections\n",
    "simple_augment = gp.SimpleAugment()\n",
    "\n",
    "# add pixel heater\n",
    "boilerPlate = $$$$<----TODO:NEED TO GENERATE/MAKE SOURCE\n",
    "\n",
    "# stack for batches\n",
    "stack = gp.Stack(batch_size)\n",
    "\n",
    "# define our network model for training\n",
    "num_fmaps = 12\n",
    "\n",
    "unet = UNet(\n",
    "  in_channels=1,\n",
    "  num_fmaps=num_fmaps,\n",
    "  fmap_inc_factor=5,\n",
    "  downsample_factors=[[2, 2, 2], [2, 2, 2]],\n",
    "  padding='valid',\n",
    "  constant_upsample=True,\n",
    "  voxel_size=[30, 30, 30] # set for each dataset\n",
    "  )\n",
    "\n",
    "model = torch.nn.Sequential(\n",
    "  unet,\n",
    "  ConvPass(num_fmaps, 1, [(1, 1, 1)], activation=None),\n",
    "  torch.nn.Sigmoid())\n",
    "\n",
    "# pick loss function\n",
    "loss = loser.MaskedMSELoss()\n",
    "\n",
    "# pick optimizer\n",
    "optimizer = torch.optim.Adam(model.parameters())\n",
    "\n",
    "# create a train node using our model, loss, and optimizer\n",
    "train = gp.torch.Train(\n",
    "  model,\n",
    "  loss,\n",
    "  optimizer,\n",
    "  inputs = {\n",
    "    'input': hot <----TODO: NEEDS TO BE HOT\n",
    "  },\n",
    "  loss_inputs = {\n",
    "    'input': prediction,\n",
    "    'mask': mask,<----TODO:NEED TO GENERATE/MAKE SOURCE\n",
    "    'target': raw <----TODO: NEED TO CROP APPROPRIATELY\n",
    "  },\n",
    "  outputs = {\n",
    "    0: prediction\n",
    "  })\n",
    "\n",
    "# create request\n",
    "TODO: DETERMINE CORRECT REQUEST ROI SIZES\n",
    "request[raw] = gp.Roi((0, 0, 0), (side_length, side_length, side_length))\n",
    "request[prediction] = gp.Roi((0, 0, 0), (side_length, side_length, side_length))\n",
    "\n",
    "# assemble pipeline\n",
    "pipeline = (source +\n",
    "            random_location +\n",
    "            simple_augment + \n",
    "            stack + \n",
    "            train)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Train"
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Examine Results"
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Build Prediction Pipeline"
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [],
   "metadata": {}
  }
 ],
 "metadata": {
  "orig_nbformat": 4,
  "language_info": {
   "name": "python",
   "version": "3.7.10",
   "mimetype": "text/x-python",
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "pygments_lexer": "ipython3",
   "nbconvert_exporter": "python",
   "file_extension": ".py"
  },
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3.7.10 64-bit ('n2v': conda)"
  },
  "interpreter": {
   "hash": "f9cb357f91f63a353a1c2ecd5237cebe3ac17167e08747c30b5061e5be51817e"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}