{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "# Imports & Other Setup"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "source": [
    "# !conda activate n2v\n",
    "%load_ext autoreload\n",
    "\n",
    "import numpy as np\n",
    "from matplotlib import pyplot as plt\n",
    "import sys\n",
    "import torch\n",
    "import random\n",
    "import zarr\n",
    "from PIL import Image\n",
    "from skimage import data\n",
    "from skimage import filters\n",
    "from skimage import metrics\n",
    "\n",
    "from funlib.learn.torch.models import UNet, ConvPass\n",
    "import gunpowder as gp\n",
    "import logging\n",
    "logging.basicConfig(level=logging.INFO)\n",
    "\n",
    "# from this repo\n",
    "import loser\n",
    "from boilerPlate import BoilerPlate\n",
    "# from segway.tasks.make_zarr_from_tiff import task_make_zarr_from_tiff_volume as tif2zarr"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "source": [
    "def imshow(raw, ground_truth=None, prediction=None):\n",
    "  rows = 1\n",
    "  if ground_truth is not None:\n",
    "    rows += 1\n",
    "  if prediction is not None:\n",
    "    rows += 1\n",
    "  cols = raw.shape[0] if len(raw.shape) > 3 else 1\n",
    "  fig, axes = plt.subplots(rows, cols, figsize=(10, 4), sharex=True, sharey=True, squeeze=False)\n",
    "  if len(raw.shape) == 3:\n",
    "    axes[0][0].imshow(raw.transpose(1, 2, 0))\n",
    "  else:\n",
    "    for i, im in enumerate(raw):\n",
    "      axes[0][i].imshow(im.transpose(1, 2, 0))\n",
    "  row = 1\n",
    "  if ground_truth is not None:\n",
    "    if len(ground_truth.shape) == 3:\n",
    "      axes[row][0].imshow(ground_truth[0])\n",
    "    else:\n",
    "      for i, gt in enumerate(ground_truth):\n",
    "        axes[row][i].imshow(gt[0])\n",
    "    row += 1\n",
    "  if prediction is not None:\n",
    "    if len(prediction.shape) == 3:\n",
    "      axes[row][0].imshow(prediction[0])\n",
    "    else:\n",
    "      for i, gt in enumerate(prediction):\n",
    "        axes[row][i].imshow(gt[0])\n",
    "  plt.show()"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Set Parameters (including data source, training variables, destination, etc.)"
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## **Paths for training, predictions and results**\n",
    "\n",
    "**`train_source:`:** This is the path to your folders containing the Training_source (noisy images). To find the path of the folder containing your datasets, go to your Files on the left of the notebook, navigate to the folder containing your files and copy the path by right-clicking on the folder, **Copy path** and pasting it into the right box below.\n",
    "\n",
    "**`model_name`:** Use only my_model -style, not my-model (Use \"_\" not \"-\"). Do not use spaces in the name. Do not re-use the name of an existing model (saved in the same folder), otherwise it will be overwritten.\n",
    "\n",
    "**`model_path`**: Enter the path where your model will be saved once trained (for instance your result folder).\n",
    "\n",
    "\n",
    "## **Training parameters**\n",
    "\n",
    "**`num_epochs`:** Input how many epochs (rounds) the network will be trained. Preliminary results can already be observed after a few (10-30) epochs, but a full training should run for 100-200 epochs. Evaluate the performance after training (see 5.). **Default value: 30**\n",
    "\n",
    "**`side_length`:** Noise2Void divides the image into patches for training. Input the size of the patches (length of a side). The value should be smaller than the dimensions of the image and divisible by 8. **Default value: 100**\n",
    "\n",
    "**If you get an Out of memory (OOM) error during the training, manually decrease the patch_size values until the OOM error disappear.**\n",
    "\n",
    "**`batch_size:`** This parameter defines the number of patches seen in each training step. Noise2Void requires a large batch size for stable training. Reduce this parameter if your GPU runs out of memory. **Default value: 1**\n",
    "\n",
    "**`num_steps`:** Define the number of training steps by epoch. By default this parameter is calculated so that each image / patch is seen at least once per epoch. **Default value: Number of patch / batch_size**\n",
    "\n",
    "**`perc_validation`:**  Input the percentage of your training dataset you want to use to validate the network during the training. **Default value: 10** \n",
    "\n",
    "**`init_learn_rate`:** Input the initial value to be used as learning rate. **Default value: 0.0004**\n",
    "\n",
    "**`perc_hotPixels:`** Percent of output pixels to designate as targets and *heat* for training **Default value: 0.198**\n"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "source": [
    "train_source = '/n/groups/htem/ESRF_id16a/tomo_ML/ReducedAnglesXray/CARE/mCTX/450p_stacks/mCTX_17keV_30nm_512c_first256.zarr' #EXPECTS TIFF VOLUME\n",
    "#TODO: MAKE ABLE TO HANDLE TIFF VOLUME OR STACK\n",
    "\n",
    "data_name = 'mCTX_17keV_30nm_512c_first256'\n",
    "data_path = '/n/groups/htem/ESRF_id16a/tomo_ML/ReducedAnglesXray/CARE/mCTX/450p_stacks/'\n",
    "data_format = 'zarr'\n",
    "\n",
    "model_name = 'noise2gun_mCTX30nm_450p'\n",
    "model_path = ''\n",
    "voxel_size=[30, 30, 30] # set for each dataset (may be able to get from zarr)\n",
    "\n",
    "side_length = 8#12 # in voxels for prediction (i.e. network output) - actual used ROI for network input will be bigger for valid padding\n",
    "unet_depth = 4 # number of layers in unet\n",
    "downsample_factor = 2\n",
    "conv_padding = 'valid'\n",
    "num_fmaps = 12\n",
    "fmap_inc_factor=5\n",
    "perc_hotPixels = 0.198\n",
    "constant_upsample=True\n",
    "\n",
    "num_epochs = 100\n",
    "batch_size = 1\n",
    "num_steps = 100\n",
    "perc_validation = 10\n",
    "init_learn_rate = 0.0004"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Make sure data source is a **zarr** "
   ],
   "metadata": {}
  },
  {
   "cell_type": "raw",
   "source": [
    "#NEEDS TO BE MADE\n",
    "\n",
    "if data_format != 'zarr':\n",
    "\n",
    "#CURRENT SCRIPT (BASH)\n",
    "# go to working directory\n",
    "cd /n/groups/htem/ESRF_id16a/tomo_ML/ReducedAnglesXray/CARE/mCTX/450p_stacks\n",
    "# cd /n/groups/htem/Segmentation/shared-nondev/cbx_fn\n",
    "\n",
    "prefix='mCTX_17keV_30nm_512c_first256'\n",
    "aligned_dir_path=\"/n/groups/htem/ESRF_id16a/tomo_ML/ReducedAnglesXray/CARE/mCTX/450p_stacks/${prefix}\"\n",
    "output_file=\"/n/groups/htem/ESRF_id16a/tomo_ML/ReducedAnglesXray/CARE/mCTX/450p_stacks/${prefix}.zarr\"\n",
    "output_dataset=\"volumes/train\"\n",
    "voxel_size='30 30 30'\n",
    "roi_offset='0 0 0'\n",
    "roi_shape='7680 15360 15360'\n",
    "x_tile_size=512\n",
    "y_tile_size=512\n",
    "section_dir_name_format=\"${prefix}_{:04d}.tif\"\n",
    "max_voxel_count=262144 # means chunk size = 256 * 1024 (recommended for NeuroGlancer chunk loading)\n",
    "\n",
    "python /n/groups/htem/users/jlr54/raygun/segway/tasks/make_zarr_from_tiff/task_make_zarr_from_tiff_single_file.py $aligned_dir_path $y_tile_size $x_tile_size $voxel_size $output_file $output_dataset --roi_offset $roi_offset --roi_shape $roi_shape --section_dir_name_format $section_dir_name_format --single_file_format 1 --max_voxel_count $max_voxel_count --no_launch_workers 0 --overwrite 0 --num_workers 4"
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Build Gunpowder Pipeline for Training\n",
    "\n",
    "### Elements are:\n",
    "\n",
    "- Data Source\n",
    "- *(optional) Normalization*\n",
    "- Random Patch Grab\n",
    "- Pixel Heating (select and mutate *hotPixels*, i.e. training targets, and keep masks)\n",
    "- Simple Augmentation (rotations/reflections)\n",
    "- Stacking\n",
    "- Training\n"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "source": [
    "# declare arrays to use in the pipeline\n",
    "raw = gp.ArrayKey('RAW') # raw data\n",
    "hot = gp.ArrayKey('HOT') # data with random pixels heated\n",
    "mask = gp.ArrayKey('MASK') # data with random pixels heated\n",
    "prediction = gp.ArrayKey('PREDICTION') # prediction of denoised data\n",
    "\n",
    "source = gp.ZarrSource(    # add the data source\n",
    "    train_source,  # the zarr container\n",
    "    {raw: 'volumes/train'},  # which dataset to associate to the array key\n",
    "    {raw: gp.ArraySpec(interpolatable=True)}  # meta-information\n",
    ")\n",
    "\n",
    "# add normalization\n",
    "# normalize = gp.Normalize(raw)\n",
    "\n",
    "# add a RandomLocation node to the pipeline to randomly select a sample\n",
    "random_location = gp.RandomLocation()\n",
    "\n",
    "# add transpositions/reflections\n",
    "simple_augment = gp.SimpleAugment()\n",
    "\n",
    "# stack for batches\n",
    "stack = gp.Stack(batch_size)\n",
    "\n",
    "# add pixel heater\n",
    "boilerPlate = BoilerPlate(raw, mask, hot, plate_size=side_length, perc_hotPixels=perc_hotPixels, ndims=3)\n",
    "\n",
    "# prepare tensors for UNet\n",
    "unsqueeze_1 = gp.Unsqueeze([hot, mask, raw])\n",
    "unsqueeze_2 = gp.Unsqueeze([hot, mask, raw])\n",
    "\n",
    "# setup a cache\n",
    "cache = gp.PreCache()\n",
    "\n",
    "# define our network model for training\n",
    "unet = UNet(\n",
    "  in_channels=1,\n",
    "  num_fmaps=num_fmaps,\n",
    "  fmap_inc_factor=fmap_inc_factor,\n",
    "  downsample_factors=[(downsample_factor,)*3,] * (unet_depth - 1),\n",
    "  padding=conv_padding,\n",
    "  constant_upsample=constant_upsample,\n",
    "  voxel_size=voxel_size # set for each dataset\n",
    "  )\n",
    "\n",
    "model = torch.nn.Sequential(\n",
    "  unet,\n",
    "  ConvPass(num_fmaps, 1, [(1, 1, 1)], activation=None),\n",
    "  torch.nn.Sigmoid())\n",
    "\n",
    "# pick loss function\n",
    "loss = loser.MaskedMSELoss()\n",
    "\n",
    "# pick optimizer\n",
    "optimizer = torch.optim.Adam(model.parameters())\n",
    "\n",
    "# create a train node using our model, loss, and optimizer\n",
    "train = gp.torch.Train(\n",
    "  model,\n",
    "  loss,\n",
    "  optimizer,\n",
    "  inputs = {\n",
    "    'input': hot\n",
    "  },\n",
    "  loss_inputs = {\n",
    "    'src': prediction,\n",
    "    'mask': mask,\n",
    "    'target': raw\n",
    "  },\n",
    "  outputs = {\n",
    "    0: prediction\n",
    "  },\n",
    "  log_dir='./tensorboard/'\n",
    "  )\n",
    "\n",
    "# figure out proper ROI padding for context\n",
    "conv_passes = 2 # set by default in unet\n",
    "kernel_size = 3 # set by default in unet\n",
    "context_side_length = 2 * np.sum([(conv_passes * (kernel_size - 1)) * (2 ** level) for level in np.arange(unet_depth - 1)]) + (conv_passes * (kernel_size - 1)) * (2 ** (unet_depth - 1)) + (conv_passes * (kernel_size - 1)) + side_length\n",
    "\n",
    "# create request\n",
    "request = gp.BatchRequest()\n",
    "request[raw] = gp.Roi(tuple(0*np.array(voxel_size)), tuple(context_side_length*np.array(voxel_size)))\n",
    "request[mask] = gp.Roi(tuple(0*np.array(voxel_size)), tuple(context_side_length*np.array(voxel_size)))\n",
    "request[hot] = gp.Roi(tuple(0*np.array(voxel_size)), tuple(context_side_length*np.array(voxel_size)))\n",
    "request[prediction] = gp.Roi(tuple(0*np.array(voxel_size)), tuple(side_length*np.array(voxel_size)))\n",
    "\n",
    "# get performance stats\n",
    "performance = gp.PrintProfilingStats(every=1000)\n",
    "\n",
    "# assemble pipeline\n",
    "pipeline = (source +\n",
    "            #normalize + \n",
    "            random_location +\n",
    "            simple_augment + \n",
    "            boilerPlate +\n",
    "            unsqueeze_1 + \n",
    "            cache +\n",
    "            #unsqueeze_2 +\n",
    "            stack + \n",
    "            train +\n",
    "            performance\n",
    "            )"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "/mnt/orchestra_nfs/users/jlr54/envs/miniconda3/envs/n2v/lib/python3.7/site-packages/torch/nn/_reduction.py:43: UserWarning: size_average and reduce args will be deprecated, please use reduction='mean' instead.\n",
      "  warnings.warn(warning.format(ret))\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Train"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "source": [
    "%autoreload\n",
    "from boilerPlate import BoilerPlate\n",
    "import loser"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "source": [
    "with gp.build(pipeline):\n",
    "  batch = pipeline.request_batch(request)\n",
    "\n",
    "imshow(batch[raw].data, batch[hot].data, batch[prediction].data)"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "INFO:gunpowder.torch.nodes.train:Starting training from scratch\n",
      "INFO:gunpowder.torch.nodes.train:Using device cuda\n",
      "INFO:gunpowder.nodes.precache:starting new set of workers (20, cache size 50)...\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "[ 0  0 46 46 46]\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "INFO:gunpowder.producer_pool:terminating workers...\n",
      "INFO:gunpowder.producer_pool:joining workers...\n",
      "INFO:gunpowder.producer_pool:done\n"
     ]
    },
    {
     "output_type": "error",
     "ename": "PipelineRequestError",
     "evalue": "Exception in pipeline:\nZarrSource[/n/groups/htem/ESRF_id16a/tomo_ML/ReducedAnglesXray/CARE/mCTX/450p_stacks/mCTX_17keV_30nm_512c_first256.zarr] -> RandomLocation -> SimpleAugment -> BoilerPlate -> Unsqueeze -> PreCache -> Stack -> Train -> PrintProfilingStats\nwhile trying to process request\n\n\tRAW: ROI: [0:3000, 0:3000, 0:3000] (3000, 3000, 3000), voxel size: None, interpolatable: None, non-spatial: False, dtype: None, placeholder: False\n\tMASK: ROI: [0:3000, 0:3000, 0:3000] (3000, 3000, 3000), voxel size: None, interpolatable: None, non-spatial: False, dtype: None, placeholder: False\n\tHOT: ROI: [0:3000, 0:3000, 0:3000] (3000, 3000, 3000), voxel size: None, interpolatable: None, non-spatial: False, dtype: None, placeholder: False\n\tPREDICTION: ROI: [0:240, 0:240, 0:240] (240, 240, 240), voxel size: None, interpolatable: None, non-spatial: False, dtype: None, placeholder: False\n",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[0;32m/mnt/orchestra_nfs/users/jlr54/envs/miniconda3/envs/n2v/lib/python3.7/site-packages/gunpowder/nodes/batch_provider.py\u001b[0m in \u001b[0;36mrequest_batch\u001b[0;34m(self, request)\u001b[0m\n\u001b[1;32m    187\u001b[0m                 \u001b[0mupstream_request\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mremove_placeholders\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 188\u001b[0;31m             \u001b[0mbatch\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprovide\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mupstream_request\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    189\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/mnt/orchestra_nfs/users/jlr54/envs/miniconda3/envs/n2v/lib/python3.7/site-packages/gunpowder/nodes/batch_filter.py\u001b[0m in \u001b[0;36mprovide\u001b[0;34m(self, request)\u001b[0m\n\u001b[1;32m    181\u001b[0m             \u001b[0mdownstream_request\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mremove_placeholders\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 182\u001b[0;31m             \u001b[0mprocessed_batch\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprocess\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnode_batch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdownstream_request\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    183\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mprocessed_batch\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/mnt/orchestra_nfs/users/jlr54/envs/miniconda3/envs/n2v/lib/python3.7/site-packages/gunpowder/nodes/generic_train.py\u001b[0m in \u001b[0;36mprocess\u001b[0;34m(self, batch, request)\u001b[0m\n\u001b[1;32m    156\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 157\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_step\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrequest\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    158\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/mnt/orchestra_nfs/users/jlr54/envs/miniconda3/envs/n2v/lib/python3.7/site-packages/gunpowder/torch/nodes/train.py\u001b[0m in \u001b[0;36mtrain_step\u001b[0;34m(self, batch, request)\u001b[0m\n\u001b[1;32m    260\u001b[0m         \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mloss\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mdevice_loss_args\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mdevice_loss_kwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 261\u001b[0;31m         \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    262\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/mnt/orchestra_nfs/users/jlr54/envs/miniconda3/envs/n2v/lib/python3.7/site-packages/torch/tensor.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(self, gradient, retain_graph, create_graph)\u001b[0m\n\u001b[1;32m    194\u001b[0m         \"\"\"\n\u001b[0;32m--> 195\u001b[0;31m         \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mautograd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgradient\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    196\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/mnt/orchestra_nfs/users/jlr54/envs/miniconda3/envs/n2v/lib/python3.7/site-packages/torch/autograd/__init__.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables)\u001b[0m\n\u001b[1;32m     98\u001b[0m         \u001b[0mtensors\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgrad_tensors\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 99\u001b[0;31m         allow_unreachable=True)  # allow_unreachable flag\n\u001b[0m\u001b[1;32m    100\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: expected dtype Float but got dtype Byte",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[0;31mBatchRequestError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m/mnt/orchestra_nfs/users/jlr54/envs/miniconda3/envs/n2v/lib/python3.7/site-packages/gunpowder/nodes/batch_provider.py\u001b[0m in \u001b[0;36mrequest_batch\u001b[0;34m(self, request)\u001b[0m\n\u001b[1;32m    187\u001b[0m                 \u001b[0mupstream_request\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mremove_placeholders\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 188\u001b[0;31m             \u001b[0mbatch\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprovide\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mupstream_request\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    189\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/mnt/orchestra_nfs/users/jlr54/envs/miniconda3/envs/n2v/lib/python3.7/site-packages/gunpowder/nodes/batch_filter.py\u001b[0m in \u001b[0;36mprovide\u001b[0;34m(self, request)\u001b[0m\n\u001b[1;32m    169\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 170\u001b[0;31m         \u001b[0mbatch\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_upstream_provider\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrequest_batch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mupstream_request\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    171\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/mnt/orchestra_nfs/users/jlr54/envs/miniconda3/envs/n2v/lib/python3.7/site-packages/gunpowder/nodes/batch_provider.py\u001b[0m in \u001b[0;36mrequest_batch\u001b[0;34m(self, request)\u001b[0m\n\u001b[1;32m    199\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 200\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mBatchRequestError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrequest\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    201\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mBatchRequestError\u001b[0m: Exception in Train while processing request\n\tRAW: ROI: [0:3000, 0:3000, 0:3000] (3000, 3000, 3000), voxel size: None, interpolatable: None, non-spatial: False, dtype: None, placeholder: False\n\tMASK: ROI: [0:3000, 0:3000, 0:3000] (3000, 3000, 3000), voxel size: None, interpolatable: None, non-spatial: False, dtype: None, placeholder: False\n\tHOT: ROI: [0:3000, 0:3000, 0:3000] (3000, 3000, 3000), voxel size: None, interpolatable: None, non-spatial: False, dtype: None, placeholder: False\n\tPREDICTION: ROI: [0:240, 0:240, 0:240] (240, 240, 240), voxel size: None, interpolatable: None, non-spatial: False, dtype: None, placeholder: False\n \nBatch returned so far:\nNone",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[0;31mBatchRequestError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m/mnt/orchestra_nfs/users/jlr54/envs/miniconda3/envs/n2v/lib/python3.7/site-packages/gunpowder/pipeline.py\u001b[0m in \u001b[0;36mrequest_batch\u001b[0;34m(self, request)\u001b[0m\n\u001b[1;32m    139\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 140\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moutput\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrequest_batch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrequest\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    141\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/mnt/orchestra_nfs/users/jlr54/envs/miniconda3/envs/n2v/lib/python3.7/site-packages/gunpowder/nodes/batch_provider.py\u001b[0m in \u001b[0;36mrequest_batch\u001b[0;34m(self, request)\u001b[0m\n\u001b[1;32m    199\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 200\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mBatchRequestError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrequest\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    201\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mBatchRequestError\u001b[0m: Exception in PrintProfilingStats while processing request\n\tRAW: ROI: [0:3000, 0:3000, 0:3000] (3000, 3000, 3000), voxel size: None, interpolatable: None, non-spatial: False, dtype: None, placeholder: False\n\tMASK: ROI: [0:3000, 0:3000, 0:3000] (3000, 3000, 3000), voxel size: None, interpolatable: None, non-spatial: False, dtype: None, placeholder: False\n\tHOT: ROI: [0:3000, 0:3000, 0:3000] (3000, 3000, 3000), voxel size: None, interpolatable: None, non-spatial: False, dtype: None, placeholder: False\n\tPREDICTION: ROI: [0:240, 0:240, 0:240] (240, 240, 240), voxel size: None, interpolatable: None, non-spatial: False, dtype: None, placeholder: False\n \nBatch returned so far:\nNone",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[0;31mPipelineRequestError\u001b[0m                      Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_26310/2658136677.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mwith\u001b[0m \u001b[0mgp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbuild\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpipeline\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m   \u001b[0mbatch\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpipeline\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrequest_batch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrequest\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mimshow\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mraw\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mhot\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mprediction\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/mnt/orchestra_nfs/users/jlr54/envs/miniconda3/envs/n2v/lib/python3.7/site-packages/gunpowder/pipeline.py\u001b[0m in \u001b[0;36mrequest_batch\u001b[0;34m(self, request)\u001b[0m\n\u001b[1;32m    140\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moutput\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrequest_batch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrequest\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    141\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 142\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mPipelineRequestError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrequest\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    143\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    144\u001b[0m     \u001b[0;34m@\u001b[0m\u001b[0mproperty\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mPipelineRequestError\u001b[0m: Exception in pipeline:\nZarrSource[/n/groups/htem/ESRF_id16a/tomo_ML/ReducedAnglesXray/CARE/mCTX/450p_stacks/mCTX_17keV_30nm_512c_first256.zarr] -> RandomLocation -> SimpleAugment -> BoilerPlate -> Unsqueeze -> PreCache -> Stack -> Train -> PrintProfilingStats\nwhile trying to process request\n\n\tRAW: ROI: [0:3000, 0:3000, 0:3000] (3000, 3000, 3000), voxel size: None, interpolatable: None, non-spatial: False, dtype: None, placeholder: False\n\tMASK: ROI: [0:3000, 0:3000, 0:3000] (3000, 3000, 3000), voxel size: None, interpolatable: None, non-spatial: False, dtype: None, placeholder: False\n\tHOT: ROI: [0:3000, 0:3000, 0:3000] (3000, 3000, 3000), voxel size: None, interpolatable: None, non-spatial: False, dtype: None, placeholder: False\n\tPREDICTION: ROI: [0:240, 0:240, 0:240] (240, 240, 240), voxel size: None, interpolatable: None, non-spatial: False, dtype: None, placeholder: False\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Examine Results"
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Build Prediction Pipeline"
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Scratch work and trouble shooting"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "source": [
    "# unet = UNet(\n",
    "#   in_channels=1,\n",
    "#   num_fmaps=10,\n",
    "#   fmap_inc_factor=5,\n",
    "#   downsample_factors=[(2, 2, 2), (2, 2, 2), (2, 2, 2)],\n",
    "#   padding='valid',\n",
    "#   constant_upsample=True,\n",
    "#   voxel_size=[30, 30, 30] # set for each dataset\n",
    "#   )\n",
    "\n",
    "# level = 0\n",
    "# downsample_factors=[(downsample_factor,)*3,] * (unet_depth - 1)\n",
    "# num_levels = len(downsample_factors) + 1\n",
    "# kernel_size_down = [[(3, 3, 3), (3, 3, 3)]]*num_levels\n",
    "\n",
    "# test = ConvPass(\n",
    "#                 1\n",
    "#                 if level == 0\n",
    "#                 else num_fmaps*fmap_inc_factor**(level - 1),\n",
    "#                 num_fmaps*fmap_inc_factor**level,\n",
    "#                 kernel_size_down[level],\n",
    "#                 activation='ReLU',\n",
    "#                 padding='valid')\n",
    "\n",
    "model.forward(torch.tensor(np.random.rand(1, 1, 100,100,100).astype(np.float32))).shape\n",
    "#test.conv_pass(torch.tensor(np.random.rand(1, 1, 100,100,100)))"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "torch.Size([1, 1, 8, 8, 8])"
      ]
     },
     "metadata": {},
     "execution_count": 20
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "source": [
    "unet.forward(torch.tensor(np.random.rand(1, 1, 100,100,100).astype(np.float32))).shape"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "torch.Size([1, 12, 8, 8, 8])"
      ]
     },
     "metadata": {},
     "execution_count": 21
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "source": [
    "a = torch.tensor(np.random.rand(1,3))\n",
    "b = torch.tensor(np.random.rand(1,3)) > 0.5\n",
    "c = torch.tensor(np.random.rand(1,3)) \n",
    "test = loss(a, b, c)\n",
    "test"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "tensor(0.0042, dtype=torch.float64)"
      ]
     },
     "metadata": {},
     "execution_count": 54
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "source": [],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "104"
      ]
     },
     "metadata": {},
     "execution_count": 47
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [],
   "outputs": [],
   "metadata": {}
  }
 ],
 "metadata": {
  "orig_nbformat": 4,
  "language_info": {
   "name": "python",
   "version": "3.7.10",
   "mimetype": "text/x-python",
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "pygments_lexer": "ipython3",
   "nbconvert_exporter": "python",
   "file_extension": ".py"
  },
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3.7.10 64-bit ('n2v': conda)"
  },
  "interpreter": {
   "hash": "f9cb357f91f63a353a1c2ecd5237cebe3ac17167e08747c30b5061e5be51817e"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}